# Music_generatorIA
Este programa crea secciones musicales con respecto a una idea principal otorgada por el usuario.

Model description

This language-music model takes BART-base fine-tunes on 282,870 English text-music pairs, where all scores are represented in ABC notation. It was introduced in the paper Exploring the Efficacy of Pre-trained Checkpoints in Text-to-Music Generation Task by Wu et al. and released in this repository.

It is capable of generating complete and semantically consistent sheet music directly from descriptions in natural language based on text. To the best of our knowledge, this is the first model that achieves text-conditional symbolic music generation which is trained on real text-music pairs, and the music is generated entirely by the model and without any hand-crafted rules.

This language-music model is available for online use and experience on Textune: Generating Tune from Text. With this online platform, you can easily input your desired text descriptions and receive a generated sheet music output from the model.

Due to copyright reasons, we are unable to publicly release the training dataset of this model. Instead, we have made available the WikiMusicText (WikiMT) dataset, which includes 1010 pairs of text-music data and can be used to evaluate the performance of language-music models.


Intended uses & limitations

You can use this model for text-conditional music generation. All scores generated by this model can be written on one stave (for vocal solo or instrumental solo) in standard classical notation, and are in a variety of styles, e.g., blues, classical, folk, jazz, pop, and world music. We recommend using the script in this repository for inference. The generated tunes are in ABC notation, and can be converted to sheet music or audio using this website, or this software.

Its creativity is limited, can not perform well on tasks requiring a high degree of creativity (e.g., melody style transfer), and it is input-sensitive. For more information, please check our paper.
